{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.76, "precision_test": 0.9642857142857143, "recall_test": 0.54, "f1_test": 0.6923076923076923, "auc_test": 0.8504}, "acc_test": 0.7, "precision_test": 0.7083333333333334, "recall_test": 0.68, "f1_test": 0.6938775510204083, "auc_test": 0.7352}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.44, "precision_test": 0.44, "recall_test": 0.44, "f1_test": 0.44, "auc_test": 0.41800000000000004, "preds": [0.8338852524757385, 0.5636053085327148, 0.9083585739135742, 0.7650577425956726, 0.008871673606336117, 0.001860851189121604, 0.7535685896873474, 0.027766704559326172, 0.016121795400977135, 0.6102923154830933, 0.019314326345920563, 0.07668460160493851, 0.6664141416549683, 0.001305862213484943, 0.8648318648338318, 0.0018025013851001859, 0.8816443681716919, 0.8695225119590759, 0.02043294347822666, 0.770222008228302, 0.943743884563446, 0.0008846897981129587, 0.13556253910064697, 0.03408634290099144, 0.7676632404327393, 0.9223175048828125, 0.009146365337073803, 0.018444731831550598, 0.005700580310076475, 0.0046623218804597855, 0.8030045032501221, 0.848602831363678, 0.0009298313525505364, 0.0015562569024041295, 0.002152903936803341, 0.19361239671707153, 0.5499404668807983, 0.5264679789543152, 0.4839429557323456, 0.9075146317481995, 0.012415586039423943, 0.014544966630637646, 0.5233497023582458, 0.08119101077318192, 0.03968405723571777, 0.7907284498214722, 0.007427398581057787, 0.5124303698539734, 0.47849223017692566, 0.01843421906232834]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.56, "precision_test": 0.56, "recall_test": 0.56, "f1_test": 0.56, "auc_test": 0.582, "preds": [0.16611476242542267, 0.43639472126960754, 0.09164140373468399, 0.2349422574043274, 0.9911283254623413, 0.9981391429901123, 0.2464313805103302, 0.9722332954406738, 0.9838782548904419, 0.38970765471458435, 0.9806857109069824, 0.9233154654502869, 0.33358582854270935, 0.998694121837616, 0.13516809046268463, 0.9981974959373474, 0.1183556318283081, 0.13047751784324646, 0.9795671105384827, 0.2297779768705368, 0.05625610053539276, 0.9991152882575989, 0.8644374012947083, 0.965913712978363, 0.23233671486377716, 0.07768242061138153, 0.9908535480499268, 0.9815552830696106, 0.9942994117736816, 0.9953376054763794, 0.19699548184871674, 0.1513971984386444, 0.9990702271461487, 0.9984437823295593, 0.9978470802307129, 0.8063875436782837, 0.45005959272384644, 0.4735319912433624, 0.516057014465332, 0.09248539805412292, 0.9875844120979309, 0.9854550361633301, 0.47665026783943176, 0.9188090562820435, 0.9603158831596375, 0.20927155017852783, 0.992572546005249, 0.4875696003437042, 0.5215077996253967, 0.9815657138824463]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.55, "precision_test": 0.5294117647058824, "recall_test": 0.9, "f1_test": 0.6666666666666667, "auc_test": 0.68, "preds": [0.5870124101638794, 0.4868158996105194, 0.5740410089492798, 0.5123761892318726, 0.5715234279632568, 0.5335438251495361, 0.5248822569847107, 0.48290398716926575, 0.5603540539741516, 0.5916457772254944, 0.5688021183013916, 0.5774537324905396, 0.5497078895568848, 0.4972725212574005, 0.5534237027168274, 0.6136202812194824, 0.5478895306587219, 0.5262045860290527, 0.5754209756851196, 0.4658517837524414, 0.582750141620636, 0.5943465232849121, 0.5646588206291199, 0.5436882376670837, 0.5076839923858643, 0.5489588975906372, 0.5770619511604309, 0.5338435769081116, 0.5292683243751526, 0.5755423903465271, 0.5225263833999634, 0.5339582562446594, 0.5669200420379639, 0.5371885299682617, 0.5299144983291626, 0.5261328220367432, 0.5851240754127502, 0.5969962477684021, 0.5823051929473877, 0.48797425627708435, 0.5542295575141907, 0.5796694159507751, 0.5731398463249207, 0.5504706501960754, 0.5771759152412415, 0.5323299169540405, 0.537261962890625, 0.5250310897827148, 0.5784314870834351, 0.5800884366035461]}
{"name": "Retrained Radar", "before": {"acc_test": 0.63, "precision_test": 0.6, "recall_test": 0.78, "f1_test": 0.6782608695652174, "auc_test": 0.6592}, "acc_test": 0.81, "precision_test": 0.7313432835820896, "recall_test": 0.98, "f1_test": 0.8376068376068375, "auc_test": 0.9532}
