{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.93, "precision_test": 0.9777777777777777, "recall_test": 0.88, "f1_test": 0.9263157894736842, "auc_test": 0.9895999999999999}, "acc_test": 0.81, "precision_test": 0.7246376811594203, "recall_test": 1.0, "f1_test": 0.8403361344537814, "auc_test": 0.9836}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.33, "precision_test": 0.2926829268292683, "recall_test": 0.24, "f1_test": 0.2637362637362637, "auc_test": 0.2016, "preds": [0.7725783586502075, 0.5269123315811157, 0.5863824486732483, 0.1173456460237503, 0.0010872880229726434, 0.8025678992271423, 0.0008718432509340346, 0.0008658052538521588, 0.0009010336943902075, 0.0008640785817988217, 0.0008693889831192791, 0.0012079339940100908, 0.0009875959949567914, 0.0008463563863188028, 0.8101941347122192, 0.7861268520355225, 0.0023297409061342478, 0.001189014408737421, 0.0008657965809106827, 0.0008653392433188856, 0.5135034918785095, 0.021152444183826447, 0.5848930478096008, 0.0008576885447837412, 0.012939332984387875, 0.015382579527795315, 0.0008686917717568576, 0.0008285389631055295, 0.08987933397293091, 0.0009648812119849026, 0.000920212478376925, 0.0008597263367846608, 0.0008480614051222801, 0.7939639687538147, 0.000883213768247515, 0.001233598217368126, 0.6607037782669067, 0.006689738016575575, 0.05089021846652031, 0.11415430903434753, 0.823981523513794, 0.0008477050578221679, 0.0011829027207568288, 0.0397862046957016, 0.0008646452915854752, 0.001396670239046216, 0.0008623768226243556, 0.0009365459554828703, 0.01781158708035946, 0.8179870247840881]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.67, "precision_test": 0.6440677966101694, "recall_test": 0.76, "f1_test": 0.6972477064220184, "auc_test": 0.7983999999999999, "preds": [0.2274215817451477, 0.4730876386165619, 0.4136175215244293, 0.8826543092727661, 0.9989126920700073, 0.19743207097053528, 0.9991281628608704, 0.9991342425346375, 0.9990990161895752, 0.9991359114646912, 0.9991306662559509, 0.9987921118736267, 0.9990123510360718, 0.9991536140441895, 0.18980588018894196, 0.21387316286563873, 0.9976702332496643, 0.9988110065460205, 0.9991342425346375, 0.9991347193717957, 0.48649656772613525, 0.9788475632667542, 0.41510695219039917, 0.9991422891616821, 0.9870606660842896, 0.9846174716949463, 0.9991313815116882, 0.9991714954376221, 0.9101207256317139, 0.999035120010376, 0.9990798234939575, 0.9991402626037598, 0.9991519451141357, 0.2060360312461853, 0.999116837978363, 0.9987664222717285, 0.33929622173309326, 0.9933102130889893, 0.9491097927093506, 0.8858457207679749, 0.17601847648620605, 0.9991523027420044, 0.9988170862197876, 0.9602137804031372, 0.999135434627533, 0.9986032843589783, 0.9991376399993896, 0.9990634322166443, 0.9821884036064148, 0.18201297521591187]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.92, "precision_test": 0.9038461538461539, "recall_test": 0.94, "f1_test": 0.9215686274509804, "auc_test": 0.9692000000000001, "preds": [0.5594642162322998, 0.5380946397781372, 0.5324183106422424, 0.5746999382972717, 0.5006870627403259, 0.5332662463188171, 0.5295863151550293, 0.563022255897522, 0.539489209651947, 0.5242846012115479, 0.5439450144767761, 0.5411523580551147, 0.5341957211494446, 0.523259162902832, 0.5449951887130737, 0.5342040657997131, 0.536834716796875, 0.5140841007232666, 0.5458201169967651, 0.5500706434249878, 0.5462670922279358, 0.53082674741745, 0.5690740346908569, 0.5300126671791077, 0.453959196805954, 0.45937392115592957, 0.5527726411819458, 0.5411379337310791, 0.4898871183395386, 0.5640215277671814, 0.5421640276908875, 0.5228434205055237, 0.5205872058868408, 0.5227025151252747, 0.5289354920387268, 0.5388036966323853, 0.5270442962646484, 0.5499741435050964, 0.5537106394767761, 0.5359988212585449, 0.5719707012176514, 0.5019351840019226, 0.548744797706604, 0.5405259728431702, 0.5385216474533081, 0.5409194827079773, 0.5197725892066956, 0.5498380064964294, 0.554857075214386, 0.5643713474273682]}
{"name": "Retrained Radar", "before": {"acc_test": 0.63, "precision_test": 0.6, "recall_test": 0.78, "f1_test": 0.6782608695652174, "auc_test": 0.7628}, "acc_test": 0.82, "precision_test": 0.7352941176470589, "recall_test": 1.0, "f1_test": 0.8474576271186441, "auc_test": 0.9995999999999999}
