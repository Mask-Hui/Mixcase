{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.79, "precision_test": 0.967741935483871, "recall_test": 0.6, "f1_test": 0.7407407407407407, "auc_test": 0.8696}, "acc_test": 0.82, "precision_test": 0.7424242424242424, "recall_test": 0.98, "f1_test": 0.8448275862068965, "auc_test": 0.9572}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.28, "precision_test": 0.17647058823529413, "recall_test": 0.12, "f1_test": 0.14285714285714282, "auc_test": 0.1324, "preds": [0.0057367864064872265, 0.0029533919878304005, 0.0008871323079802096, 0.0008833942702040076, 0.001264412421733141, 0.0008899358217604458, 0.0017663538455963135, 0.0066295494325459, 0.003846232546493411, 0.008954273536801338, 0.0010781591990962625, 0.005650226026773453, 0.001286921906284988, 0.0015290260780602694, 0.004996472969651222, 0.0008422004757449031, 0.0008524871664121747, 0.5469104647636414, 0.01744724251329899, 0.2277318388223648, 0.0009826022433117032, 0.0009329097811132669, 0.0009148429380729795, 0.001128316973336041, 0.5638272166252136, 0.0058915261179208755, 0.0010123347165063024, 0.0011298992903903127, 0.0014841880183666945, 0.0009263857500627637, 0.622509777545929, 0.7801633477210999, 0.7361464500427246, 0.0008540571434423327, 0.0012884910684078932, 0.008071347139775753, 0.0052904849871993065, 0.0022069159895181656, 0.0008931835182011127, 0.8836567401885986, 0.0012667719274759293, 0.0008522702264599502, 0.0038674762472510338, 0.008873587474226952, 0.0077147879637777805, 0.00909342896193266, 0.004309132229536772, 0.0008570439531467855, 0.0243472158908844, 0.12274438142776489]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.72, "precision_test": 0.6666666666666666, "recall_test": 0.88, "f1_test": 0.7586206896551725, "auc_test": 0.8676, "preds": [0.994263231754303, 0.9970466494560242, 0.9991129040718079, 0.9991165995597839, 0.9987356066703796, 0.9991100430488586, 0.9982336759567261, 0.9933704137802124, 0.9961537718772888, 0.9910456538200378, 0.9989218711853027, 0.9943497776985168, 0.9987131357192993, 0.9984709620475769, 0.9950035214424133, 0.9991577863693237, 0.9991475343704224, 0.45308953523635864, 0.9825527667999268, 0.7722681760787964, 0.9990173578262329, 0.9990671277046204, 0.9990851879119873, 0.9988716244697571, 0.4361727833747864, 0.9941084384918213, 0.99898761510849, 0.9988700747489929, 0.998515784740448, 0.9990736246109009, 0.37749022245407104, 0.21983666718006134, 0.2638535797595978, 0.9991459846496582, 0.9987114667892456, 0.9919286966323853, 0.9947094917297363, 0.9977930784225464, 0.9991068243980408, 0.11634323000907898, 0.9987332224845886, 0.9991477727890015, 0.996132493019104, 0.9911264777183533, 0.9922852516174316, 0.9909065961837769, 0.9956908822059631, 0.9991428852081299, 0.9756527543067932, 0.8772556185722351]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.54, "precision_test": 0.625, "recall_test": 0.2, "f1_test": 0.30303030303030304, "auc_test": 0.6988, "preds": [0.5072265267372131, 0.45028191804885864, 0.5352892875671387, 0.44415283203125, 0.4486512839794159, 0.5103256106376648, 0.45075637102127075, 0.477215439081192, 0.45948201417922974, 0.48868513107299805, 0.48601946234703064, 0.48677706718444824, 0.46551111340522766, 0.5019856691360474, 0.4650592505931854, 0.5347931385040283, 0.47270601987838745, 0.4031771421432495, 0.522239089012146, 0.48193642497062683, 0.4942578971385956, 0.499360054731369, 0.5058844685554504, 0.48834431171417236, 0.4818786680698395, 0.49622195959091187, 0.4675334095954895, 0.49060383439064026, 0.46499618887901306, 0.49338728189468384, 0.4113025367259979, 0.39819684624671936, 0.4941796660423279, 0.4630104899406433, 0.47490549087524414, 0.49725109338760376, 0.508959174156189, 0.505294919013977, 0.4944583475589752, 0.4333726465702057, 0.528602659702301, 0.4994630515575409, 0.48633041977882385, 0.4828697741031647, 0.4559984505176544, 0.43734246492385864, 0.414175808429718, 0.4701392948627472, 0.45727983117103577, 0.4705478250980377]}
{"name": "Retrained Radar", "before": {"acc_test": 0.71, "precision_test": 0.6438356164383562, "recall_test": 0.94, "f1_test": 0.7642276422764229, "auc_test": 0.7984}, "acc_test": 0.86, "precision_test": 0.7903225806451613, "recall_test": 0.98, "f1_test": 0.8749999999999999, "auc_test": 0.9904}
