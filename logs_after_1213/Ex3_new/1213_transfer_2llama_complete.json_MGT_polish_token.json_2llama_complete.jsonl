{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.93, "precision_test": 0.9777777777777777, "recall_test": 0.88, "f1_test": 0.9263157894736842, "auc_test": 0.9895999999999999}, "acc_test": 0.74, "precision_test": 0.6578947368421053, "recall_test": 1.0, "f1_test": 0.7936507936507937, "auc_test": 0.9743999999999999}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.32, "precision_test": 0.2631578947368421, "recall_test": 0.2, "f1_test": 0.22727272727272727, "auc_test": 0.19240000000000002, "preds": [0.7788723111152649, 0.4861766993999481, 0.5345160365104675, 0.07828724384307861, 0.0010140476515516639, 0.8018398284912109, 0.0008570318459533155, 0.000853204692248255, 0.0008867185679264367, 0.0008516556699760258, 0.0008574671228416264, 0.0011118566617369652, 0.0009832839714363217, 0.0008378775091841817, 0.8288410305976868, 0.8015850186347961, 0.002097422257065773, 0.0011251905234530568, 0.0008538056863471866, 0.0008527316967956722, 0.35403504967689514, 0.016400502994656563, 0.5402061939239502, 0.0008467577281408012, 0.008789929561316967, 0.01243023481220007, 0.0008545674500055611, 0.0008231793763116002, 0.032036930322647095, 0.0009361847187392414, 0.0008855644846335053, 0.0008475297945551574, 0.0008393558673560619, 0.8071703910827637, 0.0008760752971284091, 0.001114419661462307, 0.5890517830848694, 0.003549497574567795, 0.022791778668761253, 0.08363432437181473, 0.8299639821052551, 0.0008383056847378612, 0.001163675100542605, 0.02988319657742977, 0.0008516889065504074, 0.0011130934581160545, 0.0008496276568621397, 0.0009206561953760684, 0.01371332723647356, 0.8351620435714722]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.68, "precision_test": 0.6451612903225806, "recall_test": 0.8, "f1_test": 0.7142857142857142, "auc_test": 0.8076, "preds": [0.2211277037858963, 0.5138233304023743, 0.46548396348953247, 0.9217127561569214, 0.9989859461784363, 0.1981601119041443, 0.9991430044174194, 0.9991468191146851, 0.9991132616996765, 0.9991483688354492, 0.9991425275802612, 0.9988881945610046, 0.9990166425704956, 0.9991620779037476, 0.17115898430347443, 0.19841495156288147, 0.9979026317596436, 0.998874843120575, 0.9991462230682373, 0.9991472959518433, 0.6459649205207825, 0.9835995435714722, 0.4597938060760498, 0.9991532564163208, 0.9912101030349731, 0.9875697493553162, 0.9991453886032104, 0.9991768002510071, 0.9679630398750305, 0.9990637898445129, 0.999114453792572, 0.999152421951294, 0.999160647392273, 0.19282960891723633, 0.9991239905357361, 0.9988855719566345, 0.4109482169151306, 0.9964505434036255, 0.977208137512207, 0.9163656234741211, 0.17003603279590607, 0.9991617202758789, 0.99883633852005, 0.9701168537139893, 0.9991482496261597, 0.9988868832588196, 0.9991503953933716, 0.9990793466567993, 0.9862866997718811, 0.16483792662620544]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.89, "precision_test": 0.8545454545454545, "recall_test": 0.94, "f1_test": 0.8952380952380952, "auc_test": 0.9663999999999999, "preds": [0.5544006824493408, 0.5355718731880188, 0.5280460119247437, 0.571460485458374, 0.5016790628433228, 0.5323252081871033, 0.5292784571647644, 0.5629234313964844, 0.5392324328422546, 0.5221821069717407, 0.5424472093582153, 0.5389498472213745, 0.535296618938446, 0.5274053812026978, 0.5403968691825867, 0.5338537096977234, 0.5328324437141418, 0.5117644667625427, 0.5437687635421753, 0.5473994612693787, 0.5413824915885925, 0.5287466645240784, 0.5669618844985962, 0.529497504234314, 0.46730977296829224, 0.46927163004875183, 0.5500717163085938, 0.5417667031288147, 0.4964240491390228, 0.5602445006370544, 0.5400223731994629, 0.5213504433631897, 0.5218722820281982, 0.5202640891075134, 0.5313385128974915, 0.5377616882324219, 0.5220421552658081, 0.54813551902771, 0.5511342883110046, 0.532031774520874, 0.5710148811340332, 0.5040406584739685, 0.549608588218689, 0.5375918745994568, 0.539145827293396, 0.5405877232551575, 0.5229764580726624, 0.5467312335968018, 0.5501847863197327, 0.5616804957389832]}
{"name": "Retrained Radar", "before": {"acc_test": 0.63, "precision_test": 0.6, "recall_test": 0.78, "f1_test": 0.6782608695652174, "auc_test": 0.7628}, "acc_test": 0.81, "precision_test": 0.7246376811594203, "recall_test": 1.0, "f1_test": 0.8403361344537814, "auc_test": 0.996}
