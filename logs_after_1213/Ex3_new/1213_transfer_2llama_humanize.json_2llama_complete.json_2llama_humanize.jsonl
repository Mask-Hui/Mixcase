{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.79, "precision_test": 0.967741935483871, "recall_test": 0.6, "f1_test": 0.7407407407407407, "auc_test": 0.8696}, "acc_test": 0.76, "precision_test": 0.7407407407407407, "recall_test": 0.8, "f1_test": 0.7692307692307692, "auc_test": 0.804}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.28, "precision_test": 0.17647058823529413, "recall_test": 0.12, "f1_test": 0.14285714285714282, "auc_test": 0.1384, "preds": [0.006697461474686861, 0.0031647710129618645, 0.0008871487225405872, 0.0008824499673210084, 0.0016099135391414165, 0.0008883803384378552, 0.0018524217884987593, 0.010583702474832535, 0.004182829521596432, 0.010361289605498314, 0.0010430187685415149, 0.007046821527183056, 0.0013415405992418528, 0.0015929358778521419, 0.006789159961044788, 0.0008412114693783224, 0.000851945485919714, 0.5628933310508728, 0.019880812615156174, 0.49956855177879333, 0.000989974825643003, 0.000930359004996717, 0.0009101722971536219, 0.0010815102141350508, 0.608650803565979, 0.008424106985330582, 0.0010048581752926111, 0.0012514699483290315, 0.0015809045871719718, 0.0009219394414685667, 0.675045371055603, 0.790553867816925, 0.7386481165885925, 0.0008533932850696146, 0.0012379380641505122, 0.011839829385280609, 0.007411972153931856, 0.002413257258012891, 0.0008990629576146603, 0.886580765247345, 0.0013407858787104487, 0.0008517596288584173, 0.0053706904873251915, 0.00861318688839674, 0.011530878022313118, 0.013527440838515759, 0.004417648538947105, 0.0008564488380216062, 0.02361641637980938, 0.11549791693687439]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.72, "precision_test": 0.6666666666666666, "recall_test": 0.88, "f1_test": 0.7586206896551725, "auc_test": 0.8616, "preds": [0.993302583694458, 0.9968352913856506, 0.9991127848625183, 0.9991175532341003, 0.9983900785446167, 0.9991115927696228, 0.9981476068496704, 0.9894163012504578, 0.9958171248435974, 0.9896386861801147, 0.9989569187164307, 0.9929531216621399, 0.9986584186553955, 0.9984070658683777, 0.9932108521461487, 0.9991587400436401, 0.9991480112075806, 0.4371066987514496, 0.9801192283630371, 0.500431478023529, 0.9990099668502808, 0.9990696310997009, 0.9990898370742798, 0.9989185333251953, 0.391349196434021, 0.9915758967399597, 0.9989951252937317, 0.9987485408782959, 0.9984190464019775, 0.9990780353546143, 0.3249545991420746, 0.20944619178771973, 0.26135194301605225, 0.999146580696106, 0.9987621307373047, 0.9881601333618164, 0.9925881028175354, 0.997586727142334, 0.999100923538208, 0.11341921985149384, 0.9986592531204224, 0.9991482496261597, 0.9946293234825134, 0.9913868308067322, 0.9884691834449768, 0.9864726066589355, 0.9955824017524719, 0.9991434812545776, 0.9763835668563843, 0.8845020532608032]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.54, "precision_test": 0.5238095238095238, "recall_test": 0.88, "f1_test": 0.6567164179104478, "auc_test": 0.6648000000000001, "preds": [0.5991137027740479, 0.4985613226890564, 0.5754223465919495, 0.5176866054534912, 0.5894871950149536, 0.5279760360717773, 0.5528820753097534, 0.4895387291908264, 0.5589901208877563, 0.6129225492477417, 0.5792080760002136, 0.5774595737457275, 0.554872989654541, 0.4860530495643616, 0.5863026976585388, 0.6199080348014832, 0.56224125623703, 0.49515700340270996, 0.5572150945663452, 0.4689502418041229, 0.5782638788223267, 0.6004714369773865, 0.5508077144622803, 0.5482731461524963, 0.49543625116348267, 0.5426622033119202, 0.5772592425346375, 0.5474462509155273, 0.5074275732040405, 0.5621371269226074, 0.5136922001838684, 0.5061656832695007, 0.5727722644805908, 0.5534856915473938, 0.5320305228233337, 0.5327444076538086, 0.5812060832977295, 0.5967932343482971, 0.5767729878425598, 0.5066111087799072, 0.5566800832748413, 0.60455322265625, 0.5486255288124084, 0.5400904417037964, 0.5650777816772461, 0.5217023491859436, 0.5309805870056152, 0.5023400783538818, 0.5539336800575256, 0.5679035782814026]}
{"name": "Retrained Radar", "before": {"acc_test": 0.71, "precision_test": 0.6438356164383562, "recall_test": 0.94, "f1_test": 0.7642276422764229, "auc_test": 0.7984}, "acc_test": 0.81, "precision_test": 0.7313432835820896, "recall_test": 0.98, "f1_test": 0.8376068376068375, "auc_test": 0.9863999999999999}
