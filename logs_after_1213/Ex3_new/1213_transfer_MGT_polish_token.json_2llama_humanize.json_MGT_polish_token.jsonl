{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.5, "precision_test": 0.5, "recall_test": 0.02, "f1_test": 0.038461538461538464, "auc_test": 0.388}, "acc_test": 0.47, "precision_test": 0.36363636363636365, "recall_test": 0.08, "f1_test": 0.13114754098360654, "auc_test": 0.3772}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.39, "precision_test": 0.4, "recall_test": 0.44, "f1_test": 0.41904761904761906, "auc_test": 0.34040000000000004, "preds": [0.06809183955192566, 0.6331490874290466, 0.019163252785801888, 0.006003339774906635, 0.5546020865440369, 0.8581903576850891, 0.8846648335456848, 0.0008783290977589786, 0.9795370101928711, 0.5374908447265625, 0.008841999806463718, 0.9571523666381836, 0.0008907553274184465, 0.00636910879984498, 0.05413539335131645, 0.006169833708554506, 0.003813812742009759, 0.000963273923844099, 0.000889972725417465, 0.4409244656562805, 0.7428290247917175, 0.5411591529846191, 0.5475205779075623, 0.016369547694921494, 0.0008710887632332742, 0.0011308068642392755, 0.07191075384616852, 0.0008557930123060942, 0.8187514543533325, 0.14578692615032196, 0.8159841895103455, 0.9751670360565186, 0.0008638687431812286, 0.9044023156166077, 0.6277989745140076, 0.001141910906881094, 0.004242975264787674, 0.89212965965271, 0.01904214173555374, 0.9915279150009155, 0.002087906701490283, 0.9868393540382385, 0.001213179319165647, 0.9520073533058167, 0.0011091516353189945, 0.9335737228393555, 0.9981104135513306, 0.005694739520549774, 0.0054603805765509605, 0.8959372639656067]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.61, "precision_test": 0.6222222222222222, "recall_test": 0.56, "f1_test": 0.5894736842105264, "auc_test": 0.6596000000000001, "preds": [0.9319081902503967, 0.36685091257095337, 0.9808366894721985, 0.9939966201782227, 0.4453979432582855, 0.1418096274137497, 0.11533515900373459, 0.9991217255592346, 0.020462999120354652, 0.4625091850757599, 0.9911579489707947, 0.04284755140542984, 0.9991092085838318, 0.9936309456825256, 0.9458645582199097, 0.993830144405365, 0.9961861968040466, 0.9990367889404297, 0.9991100430488586, 0.5590754747390747, 0.25717100501060486, 0.45884084701538086, 0.45247942209243774, 0.9836304187774658, 0.9991288781166077, 0.9988691210746765, 0.9280892610549927, 0.9991441965103149, 0.18124859035015106, 0.8542130589485168, 0.18401576578617096, 0.024832967668771744, 0.9991361498832703, 0.09559769183397293, 0.37220102548599243, 0.9988580942153931, 0.9957570433616638, 0.10787032544612885, 0.9809578657150269, 0.008472014218568802, 0.9979121088981628, 0.013160699978470802, 0.9987868666648865, 0.04799268767237663, 0.9988908171653748, 0.06642629951238632, 0.0018896107794716954, 0.9943051934242249, 0.9945396780967712, 0.10406267642974854]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.33, "precision_test": 0.36065573770491804, "recall_test": 0.44, "f1_test": 0.3963963963963964, "auc_test": 0.2696, "preds": [0.4865320324897766, 0.4474480450153351, 0.5189306139945984, 0.48784881830215454, 0.44457849860191345, 0.5013695955276489, 0.4729689061641693, 0.4965645670890808, 0.5163719654083252, 0.45141667127609253, 0.5149704813957214, 0.5444136261940002, 0.4919481575489044, 0.4700789153575897, 0.5068015456199646, 0.5388755798339844, 0.5011927485466003, 0.4596156179904938, 0.49904245138168335, 0.5304763913154602, 0.44900038838386536, 0.4927090108394623, 0.5294255018234253, 0.49979665875434875, 0.44403141736984253, 0.4569457769393921, 0.5616493225097656, 0.5790393352508545, 0.4589591920375824, 0.5000693798065186, 0.549747109413147, 0.4775204062461853, 0.5712377429008484, 0.4934084713459015, 0.4682309627532959, 0.4894864559173584, 0.48961731791496277, 0.5077530145645142, 0.4575440287590027, 0.5055263638496399, 0.49845796823501587, 0.44438228011131287, 0.5065661668777466, 0.4624844491481781, 0.48277345299720764, 0.5016688108444214, 0.48844632506370544, 0.522108793258667, 0.5082218050956726, 0.5068305730819702]}
{"name": "Retrained Radar", "before": {"acc_test": 0.39, "precision_test": 0.36585365853658536, "recall_test": 0.3, "f1_test": 0.3296703296703297, "auc_test": 0.3444}, "acc_test": 0.53, "precision_test": 0.5333333333333333, "recall_test": 0.48, "f1_test": 0.505263157894737, "auc_test": 0.5612}
