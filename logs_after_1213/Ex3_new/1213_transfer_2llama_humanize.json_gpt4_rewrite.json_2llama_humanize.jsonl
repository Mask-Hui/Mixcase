{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.9, "precision_test": 0.9761904761904762, "recall_test": 0.82, "f1_test": 0.8913043478260869, "auc_test": 0.9828}, "acc_test": 0.78, "precision_test": 0.75, "recall_test": 0.84, "f1_test": 0.7924528301886793, "auc_test": 0.8288}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.62, "precision_test": 0.5882352941176471, "recall_test": 0.8, "f1_test": 0.6779661016949153, "auc_test": 0.6624, "preds": [0.8730997443199158, 0.8471664786338806, 0.11233698576688766, 0.7725380659103394, 0.8985531330108643, 0.9438807368278503, 0.5767512321472168, 0.04673730209469795, 0.6492658257484436, 0.5207352638244629, 0.0024216107558459044, 0.0940575823187828, 0.5755523443222046, 0.5118907690048218, 0.7653538584709167, 0.02731737308204174, 0.973036527633667, 0.8497047424316406, 0.8157021999359131, 0.13633520901203156, 0.8415828347206116, 0.7212986350059509, 0.5192448496818542, 0.04775514826178551, 0.9448867440223694, 0.9528046250343323, 0.838360607624054, 0.018427632749080658, 0.5944985747337341, 0.7351142168045044, 0.5143995881080627, 0.9616097211837769, 0.6214953064918518, 0.5498011708259583, 0.9237511157989502, 0.6404373049736023, 0.771347165107727, 0.5393639206886292, 0.9222550988197327, 0.8875753879547119, 0.840836763381958, 0.07583297789096832, 0.6692896485328674, 0.8461288213729858, 0.9069495797157288, 0.9684328436851501, 0.6277754306793213, 0.14226973056793213, 0.8314675688743591, 0.9656928777694702]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.38, "precision_test": 0.3125, "recall_test": 0.2, "f1_test": 0.24390243902439027, "auc_test": 0.3376, "preds": [0.12690019607543945, 0.1528335064649582, 0.8876630067825317, 0.22746190428733826, 0.10144682228565216, 0.05611923336982727, 0.4232487976551056, 0.9532627463340759, 0.3507342040538788, 0.47926467657089233, 0.9975784420967102, 0.9059423804283142, 0.4244476556777954, 0.4881092607975006, 0.23464615643024445, 0.9726826548576355, 0.026963461190462112, 0.15029531717300415, 0.1842978149652481, 0.8636648058891296, 0.158417209982872, 0.2787013649940491, 0.48075512051582336, 0.9522448778152466, 0.055113308131694794, 0.047195348888635635, 0.16163939237594604, 0.9815723896026611, 0.40550145506858826, 0.264885812997818, 0.48560044169425964, 0.03839028626680374, 0.3785046935081482, 0.45019885897636414, 0.07624883204698563, 0.3595626652240753, 0.22865284979343414, 0.4606361389160156, 0.07774495333433151, 0.11242466419935226, 0.1591632217168808, 0.9241670370101929, 0.33071038126945496, 0.15387120842933655, 0.09305042028427124, 0.031567152589559555, 0.3722245991230011, 0.8577302694320679, 0.16853247582912445, 0.034307170659303665]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.54, "precision_test": 0.5238095238095238, "recall_test": 0.88, "f1_test": 0.6567164179104478, "auc_test": 0.5883999999999998, "preds": [0.5924448370933533, 0.5386110544204712, 0.5741138458251953, 0.4861302971839905, 0.5749943852424622, 0.517894446849823, 0.5212035775184631, 0.4237799048423767, 0.5353761315345764, 0.5697273015975952, 0.5794489979743958, 0.57725590467453, 0.5093116164207458, 0.4768192768096924, 0.5033009052276611, 0.5787842869758606, 0.5354518890380859, 0.5360777974128723, 0.5556729435920715, 0.4575481712818146, 0.5686640739440918, 0.5660438537597656, 0.5413261651992798, 0.5263440608978271, 0.4947328269481659, 0.5195736289024353, 0.5848156213760376, 0.5365697145462036, 0.5106880068778992, 0.5671102404594421, 0.535385251045227, 0.5258387923240662, 0.5589979290962219, 0.5178506374359131, 0.4943651556968689, 0.5225383043289185, 0.5761598348617554, 0.5801292061805725, 0.5799996256828308, 0.513485848903656, 0.5690494179725647, 0.5852317810058594, 0.5438467264175415, 0.5641903877258301, 0.5376753211021423, 0.5180666446685791, 0.5218586921691895, 0.522936999797821, 0.557664692401886, 0.5131527781486511]}
{"name": "Retrained Radar", "before": {"acc_test": 0.56, "precision_test": 0.5517241379310345, "recall_test": 0.64, "f1_test": 0.5925925925925927, "auc_test": 0.5596}, "acc_test": 0.82, "precision_test": 0.7352941176470589, "recall_test": 1.0, "f1_test": 0.8474576271186441, "auc_test": 0.9643999999999999}
