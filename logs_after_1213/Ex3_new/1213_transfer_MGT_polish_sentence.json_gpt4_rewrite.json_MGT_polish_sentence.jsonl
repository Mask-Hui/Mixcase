{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.9, "precision_test": 0.9761904761904762, "recall_test": 0.82, "f1_test": 0.8913043478260869, "auc_test": 0.9828}, "acc_test": 0.92, "precision_test": 0.875, "recall_test": 0.98, "f1_test": 0.9245283018867924, "auc_test": 0.9516}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.63, "precision_test": 0.5915492957746479, "recall_test": 0.84, "f1_test": 0.6942148760330579, "auc_test": 0.6632, "preds": [0.9106907844543457, 0.8935317993164062, 0.2784769833087921, 0.8161805868148804, 0.928923487663269, 0.9770547151565552, 0.6852303147315979, 0.06025359407067299, 0.7525608539581299, 0.5652734637260437, 0.00370260258205235, 0.7714232802391052, 0.6700292229652405, 0.5695865154266357, 0.813162088394165, 0.10757116228342056, 0.9924707412719727, 0.8865277171134949, 0.8553873300552368, 0.49275651574134827, 0.8803485631942749, 0.7869896292686462, 0.5563786625862122, 0.06589562445878983, 0.9751601815223694, 0.9818820357322693, 0.8806623220443726, 0.03626561164855957, 0.6922552585601807, 0.8045225143432617, 0.5541754961013794, 0.9870679974555969, 0.7261075377464294, 0.657681941986084, 0.9609278440475464, 0.7106547355651855, 0.8135729432106018, 0.6103217005729675, 0.9581112265586853, 0.9283955693244934, 0.8804644346237183, 0.1571797877550125, 0.76280277967453, 0.8960803747177124, 0.9409065246582031, 0.9899907112121582, 0.7381841540336609, 0.5048543214797974, 0.8783475160598755, 0.9893184304237366]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.37, "precision_test": 0.27586206896551724, "recall_test": 0.16, "f1_test": 0.20253164556962025, "auc_test": 0.3368, "preds": [0.08930917084217072, 0.10646815598011017, 0.7215229868888855, 0.18381941318511963, 0.07107648253440857, 0.02294527180492878, 0.3147696852684021, 0.9397464394569397, 0.24743910133838654, 0.4347265362739563, 0.9962974190711975, 0.22857676446437836, 0.32997074723243713, 0.43041354417800903, 0.18683786690235138, 0.8924288153648376, 0.007529239635914564, 0.11347226053476334, 0.14461266994476318, 0.5072434544563293, 0.11965145170688629, 0.21301040053367615, 0.44362130761146545, 0.9341044425964355, 0.024839824065566063, 0.018117932602763176, 0.11933769285678864, 0.9637343883514404, 0.30774471163749695, 0.19547748565673828, 0.445824533700943, 0.012931990437209606, 0.27389243245124817, 0.34231802821159363, 0.03907213360071182, 0.28934523463249207, 0.18642708659172058, 0.3896782696247101, 0.0418887622654438, 0.07160446047782898, 0.11953561007976532, 0.8428202271461487, 0.2371971607208252, 0.1039196327328682, 0.0590934231877327, 0.010009298101067543, 0.2618159055709839, 0.495145708322525, 0.1216525137424469, 0.01068158634006977]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.6, "precision_test": 0.578125, "recall_test": 0.74, "f1_test": 0.6491228070175439, "auc_test": 0.6576000000000001, "preds": [0.5612749457359314, 0.47162926197052, 0.5537768006324768, 0.49038442969322205, 0.5330073833465576, 0.5149969458580017, 0.4831381142139435, 0.48088887333869934, 0.508354127407074, 0.5559362769126892, 0.5594874620437622, 0.5508953332901001, 0.45789939165115356, 0.5606474876403809, 0.5069782733917236, 0.5593478083610535, 0.506046712398529, 0.5112053751945496, 0.5622554421424866, 0.48140081763267517, 0.5033499002456665, 0.5648615956306458, 0.5592213869094849, 0.49983981251716614, 0.5228445529937744, 0.5501735210418701, 0.5205599069595337, 0.5309669375419617, 0.48033612966537476, 0.550580620765686, 0.49191975593566895, 0.5190774202346802, 0.5355973839759827, 0.5270077586174011, 0.48091232776641846, 0.5435190200805664, 0.5233607292175293, 0.5595368146896362, 0.5368146300315857, 0.4552801251411438, 0.5795338153839111, 0.5767467021942139, 0.49625736474990845, 0.5545094609260559, 0.5415502786636353, 0.5376618504524231, 0.5108100771903992, 0.5232841968536377, 0.4920271933078766, 0.5185685157775879]}
{"name": "Retrained Radar", "before": {"acc_test": 0.56, "precision_test": 0.5517241379310345, "recall_test": 0.64, "f1_test": 0.5925925925925927, "auc_test": 0.5596}, "acc_test": 0.74, "precision_test": 0.6666666666666666, "recall_test": 0.96, "f1_test": 0.7868852459016393, "auc_test": 0.8715999999999999}
