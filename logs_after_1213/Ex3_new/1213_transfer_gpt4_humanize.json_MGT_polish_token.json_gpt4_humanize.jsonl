{"name": "Retrained GPT-sentinel", "before": {"acc_test": 0.93, "precision_test": 0.9777777777777777, "recall_test": 0.88, "f1_test": 0.9263157894736842, "auc_test": 0.9895999999999999}, "acc_test": 0.78, "precision_test": 0.6944444444444444, "recall_test": 1.0, "f1_test": 0.819672131147541, "auc_test": 0.95}
{"name": "Retrainedroberta-base-openai-detector", "acc_test": 0.37, "precision_test": 0.2903225806451613, "recall_test": 0.18, "f1_test": 0.22222222222222224, "auc_test": 0.21200000000000002, "preds": [0.7145534753799438, 0.11005601286888123, 0.1809985488653183, 0.06264042109251022, 0.0010358316358178854, 0.7404181957244873, 0.0008615312981419265, 0.0008566668839193881, 0.0008985003223642707, 0.0008551355567760766, 0.0008628576761111617, 0.00108597322832793, 0.0009771959157660604, 0.0008431345922872424, 0.8083221316337585, 0.7730950713157654, 0.0018824009457603097, 0.0010470857378095388, 0.0008582870359532535, 0.0008561110589653254, 0.15088213980197906, 0.01447200309485197, 0.5096080899238586, 0.000850564509164542, 0.0058506871573626995, 0.010160517878830433, 0.0008612226811237633, 0.0008295797160826623, 0.023789361119270325, 0.0009354812209494412, 0.0009179465705528855, 0.0008510849438607693, 0.0008444475824944675, 0.7780699133872986, 0.0008761666249483824, 0.0010931084398180246, 0.5167126059532166, 0.0028852098621428013, 0.014596152119338512, 0.0732608437538147, 0.7996084690093994, 0.0008439087541773915, 0.001120643224567175, 0.0316438302397728, 0.0008565085008740425, 0.0013255360536277294, 0.000854465295560658, 0.0009043864556588233, 0.008747096173465252, 0.8232375383377075]}
{"name": "RetrainedHello-SimpleAI/chatgpt-detector-roberta", "acc_test": 0.63, "precision_test": 0.5942028985507246, "recall_test": 0.82, "f1_test": 0.6890756302521008, "auc_test": 0.7879999999999999, "preds": [0.28544655442237854, 0.8899439573287964, 0.8190014362335205, 0.9373595714569092, 0.9989641904830933, 0.2595817744731903, 0.9991384744644165, 0.9991433620452881, 0.9991015195846558, 0.9991447925567627, 0.9991372227668762, 0.9989140033721924, 0.9990228414535522, 0.9991568326950073, 0.19167782366275787, 0.22690492868423462, 0.9981175661087036, 0.9989528656005859, 0.9991416931152344, 0.9991438388824463, 0.8491178750991821, 0.9855279326438904, 0.49039193987846375, 0.9991494417190552, 0.9941493272781372, 0.9898395538330078, 0.9991387128829956, 0.9991704225540161, 0.9762105941772461, 0.9990645051002502, 0.999082088470459, 0.9991488456726074, 0.9991555213928223, 0.22193007171154022, 0.9991238713264465, 0.9989068508148193, 0.48328742384910583, 0.9971147775650024, 0.985403835773468, 0.9267390966415405, 0.20039153099060059, 0.99915611743927, 0.9988793730735779, 0.968356192111969, 0.9991434812545776, 0.9986745119094849, 0.9991455078125, 0.9990956783294678, 0.9912529587745667, 0.1767624169588089]}
{"name": "Retraineddistilbert-base-uncased", "acc_test": 0.65, "precision_test": 0.5903614457831325, "recall_test": 0.98, "f1_test": 0.7368421052631579, "auc_test": 0.8392000000000001, "preds": [0.5325461030006409, 0.5231061577796936, 0.541111409664154, 0.5594541430473328, 0.5131243467330933, 0.5421369075775146, 0.5680709481239319, 0.556861162185669, 0.5497971177101135, 0.5374135375022888, 0.5325155258178711, 0.559514045715332, 0.5521232485771179, 0.5567204356193542, 0.5147550702095032, 0.5492123365402222, 0.5548155307769775, 0.5464903116226196, 0.5253969430923462, 0.5509613752365112, 0.544416069984436, 0.5221524238586426, 0.5194498896598816, 0.5367915034294128, 0.5092589855194092, 0.517855703830719, 0.5560691356658936, 0.589126467704773, 0.5263888239860535, 0.5740940570831299, 0.5355333089828491, 0.5752396583557129, 0.5356438755989075, 0.5290789008140564, 0.5204818844795227, 0.5504738688468933, 0.4850963354110718, 0.5157512426376343, 0.5576798915863037, 0.5494442582130432, 0.5085810422897339, 0.5139949321746826, 0.517577588558197, 0.5473476648330688, 0.5576750040054321, 0.5362012386322021, 0.554564893245697, 0.5562056303024292, 0.5461812019348145, 0.5169697403907776]}
{"name": "Retrained Radar", "before": {"acc_test": 0.63, "precision_test": 0.6, "recall_test": 0.78, "f1_test": 0.6782608695652174, "auc_test": 0.7628}, "acc_test": 0.98, "precision_test": 0.9615384615384616, "recall_test": 1.0, "f1_test": 0.9803921568627451, "auc_test": 0.9995999999999999}
