Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (pspnet). Our global prior representation is effective to produce good quality results on the scene parsing task, while pspnet provides a superior framework for pixel-level prediction tasks. The proposed approach achieves state-of-the-art performance on various datasets. It came first in imagenet scene parsing challenge 2016, pascal voc 2012 benchmark and cityscapes benchmark. A single pspnet yields new record of miou accuracy 85.4% on pascal voc 2012 and accuracy 80.2% on cityscapes.