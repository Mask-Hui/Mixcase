This paper studies monocular visual odometry (vo) problem. Most of existing vo algorithms are developed under a standard pipeline including feature extraction, feature matching, motion estimation, local optimisation, etc. Although some of them have demonstrated superior performance, they usually need to be carefully designed and specifically fine-tuned to work well in different environments. Some prior knowledge is also required to recover an absolute scale for monocular vo. This paper presents a novel end-to-end framework for monocular vo by using deep recurrent convolutional neural networks (rcnns). Since it is trained and deployed in an end-to-end manner, it infers poses directly from a sequence of raw rgb images (videos) without adopting any module in the conventional vo pipeline. Based on the rcnns, it not only automatically learns effective feature representation for the vo problem through convolutional neural networks, but also implicitly models sequential dynamics and relations using deep recurrent neural networks. Extensive experiments on the kitti vo dataset show competitive performance to state-of-the-art methods, verifying that the end-to-end deep learning technique can be a viable complement to the traditional vo systems.