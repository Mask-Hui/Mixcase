We present deepwalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. Deepwalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. Deepwalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate deepwalk's latent representations on several multi-label network classification tasks for social networks such as blogcatalog, flickr, and youtube. Our results show that deepwalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. Deepwalk's representations can provide f1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, deepwalk's representations are able to outperform all baseline methods while using 60% less training data. Deepwalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.