Neural random fields (NRFs), referring to a class of generative models that
use neural networks to implement potential functions in random fields (a.k.a.
energy-based models), are not new but receive less attention with slow
progress. Different from various directed graphical models such as generative
adversarial networks (GANs), NRFs provide an interesting family of undirected
graphical models for generative modeling. In this paper we propose a new
approach, the inclusive-NRF approach, to learning NRFs for continuous data
(e.g. images), by introducing inclusive-divergence minimized auxiliary
generators and developing stochastic gradient sampling in an augmented space.
Based on the new approach, specific inclusive-NRF models are developed and
thoroughly evaluated in two important generative modeling applications - image
generation and anomaly detection. The proposed models consistently improve over
state-of-the-art results in both applications. Remarkably, in addition to
superior sample generation, one additional benefit of our inclusive-NRF
approach is that, unlike GANs, it can directly provide (unnormalized) density
estimate for sample evaluation. With these contributions and results, this
paper significantly advances the learning and applications of NRFs to a new
level, both theoretically and empirically, which have never been obtained
before.