Neural random fields (nrfs), referring to a class of generative models that use neural networks to implement potential functions in random fields (a.k.a. Energy-based models), are not new but receive less attention with slow progress. Different from various directed graphical models such as generative adversarial networks (gans), nrfs provide an interesting family of undirected graphical models for generative modeling. In this paper we propose a new approach, the inclusive-nrf approach, to learning nrfs for continuous data (e.g. Images), by introducing inclusive-divergence minimized auxiliary generators and developing stochastic gradient sampling in an augmented space. Based on the new approach, specific inclusive-nrf models are developed and thoroughly evaluated in two important generative modeling applications - image generation and anomaly detection. The proposed models consistently improve over state-of-the-art results in both applications. Remarkably, in addition to superior sample generation, one additional benefit of our inclusive-nrf approach is that, unlike gans, it can directly provide (unnormalized) density estimate for sample evaluation. With these contributions and results, this paper significantly advances the learning and applications of nrfs to a new level, both theoretically and empirically, which have never been obtained before.