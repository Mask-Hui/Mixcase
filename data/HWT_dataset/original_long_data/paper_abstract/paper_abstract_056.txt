Sound sources localization using multichannel signal processing has been a
subject of active research for decades. In recent years, the use of deep
learning in audio signal processing has allowed to drastically improve
performances for machine hearing. This has motivated the scientific community
to also develop machine learning strategies for source localization
applications. In this paper, we present BeamLearning, a multi-resolution deep
learning approach that allows to encode relevant information contained in
unprocessed time domain acoustic signals captured by microphone arrays. The use
of raw data aims at avoiding simplifying hypothesis that most traditional
model-based localization methods rely on. Benefits of its use are shown for
realtime sound source 2D-localization tasks in reverberating and noisy
environments. Since supervised machine learning approaches require large-sized,
physically realistic, precisely labelled datasets, we also developed a fast
GPU-based computation of room impulse responses using fractional delays for
image source models. A thorough analysis of the network representation and
extensive performance tests are carried out using the BeamLearning network with
synthetic and experimental datasets. Obtained results demonstrate that the
BeamLearning approach significantly outperforms the wideband MUSIC and SRP-PHAT
methods in terms of localization accuracy and computational efficiency in
presence of heavy measurement noise and reverberation.