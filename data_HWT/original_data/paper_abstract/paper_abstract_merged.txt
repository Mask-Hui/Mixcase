We introduce a neural network with a recurrent attention model over a possibly large external memory.
The architecture is a form of memory network (weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings.
It can also be seen as an extension of rnnsearch to the case where multiple computational steps (hops) are performed per output symbol.
The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling.
For the former our approach is competitive with memory networks, but with less supervision.
For the latter, on the penn treebank and text8 datasets our approach demonstrates comparable performance to rnns and lstms.
In both cases we show that the key concept of multiple computational hops yields improved results.neural machine translation is a recently proposed approach to machine translation.
Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance.
The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation.
In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly.
With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of english-to-french translation.
Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.
This paper deals with the problem of audio source separation.
To handle the complex and ill-posed nature of the problems of audio source separation, the current state-of-the-art approaches employ deep neural networks to obtain instrumental spectra from a mixture.
In this study, we propose a novel network architecture that extends the recently developed densely connected convolutional network (densenet), which has shown excellent results on image classification tasks.
To deal with the specific problem of audio source separation, an up-sampling layer, block skip connection and band-dedicated dense blocks are incorporated on top of densenet.
The proposed approach takes advantage of long contextual information and outperforms state-of-the-art results on sisec 2016 competition by a large margin in terms of signal-to-distortion ratio.
Moreover, the proposed architecture requires significantly fewer parameters and considerably less training time compared with other methods.the dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration.
The best performing such models also connect the encoder and decoder through an attentionm echanisms.
We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train.
Our single model with 165 million parameters, achieves 27.5 bleu onenglish-to-german translation, improving over the existing best ensemble result by over 1 bleu.
On english-to-french translation, we outperform the previoussingle state-of-the-art with model by 0.7 bleu, achieving a bleu score of 41.1.generating music has a few notable differences from generating images and videos.
First, music is an art of time, necessitating a temporal model.
Second, music is usually composed of multiple instruments/tracks with their own temporal dynamics, but collectively they unfold over time interdependently.
Lastly, musical notes are often grouped into chords, arpeggios or melodies in polyphonic music, and thereby introducing a chronological ordering of notes is not naturally suitable.
In this paper, we propose three models for symbolic multi-track music generation under the framework of generative adversarial networks (gans).
The three models, which differ in the underlying assumptions and accordingly the network architectures, are referred to as the jamming model, the composer model and the hybrid model.
We trained the proposed models on a dataset of over one hundred thousand bars of rock music and applied them to generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.
A few intra-track and inter-track objective metrics are also proposed to evaluate the generative results, in addition to a subjective user study.
We show that our models can generate coherent music of four bars right from scratch (i.e.
Without human inputs).
We also extend our models to human-ai cooperative music generation: given a specific track composed by human, we can generate four additional tracks to accompany it.
All code, the dataset and the rendered audio samples are available at this https url .we present compositional attention networks, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning.
While many types of neural networks are effective at learning and generalizing from massive quantities of data, this model moves away from monolithic black-box architectures towards a design that provides a strong prior for iterative reasoning, enabling it to support explainable and structured learning, as well as generalization from a modest amount of data.
The model builds on the great success of existing recurrent cells such as lstms: it sequences a single recurrent memory, attention, and control (mac) cell, and by careful design imposes structural constraints on the operation of each cell and the interactions between them, incorporating explicit control and soft attention mechanisms into their interfaces.
We demonstrate the model's strength and robustness on the challenging clevr dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model.
More importantly, we show that the new model is more computationally efficient, data-efficient, and requires an order of magnitude less time and/or data to achieve good results.an attentional mechanism has lately been used to improve neural machine translation (nmt) by selectively focusing on parts of the source sentence during translation.
However, there has been little work exploring useful architectures for attention-based nmt.
This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time.
We demonstrate the effectiveness of both approaches over the wmt translation tasks between english and german in both directions.
With local attention, we achieve a significant gain of 5.0 bleu points over non-attentional systems which already incorporate known techniques such as dropout.
Our ensemble model using different attention architectures has established a new state-of-the-art result in the wmt'15 english to german translation task with 25.9 bleu points, an improvement of 1.0 bleu points over the existing best system backed by nmt and an n-gram reranker.we propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent.
Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates.
The new methods, which we call proximal policy optimization (ppo), have some of the benefits of trust region policy optimization (trpo), but they are much simpler to implement, more general, and have better sample complexity (empirically).
Our experiments test ppo on a collection of benchmark tasks, including simulated robotic locomotion and atari game playing, and we show that ppo outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network.
To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization.
This approach provides us with a broad and unifying view on much prior work on this topic.
Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal.
In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries.
These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks.
They also suggest robustness against a first-order adversary as a natural security guarantee.
We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.planning has been very successful for control tasks with known environment dynamics.
To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world.
However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains.
We propose the deep planning network (planet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space.
To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps.
We approach this using a latent dynamics model with both deterministic and stochastic transition components.
Moreover, we propose a multi-step variational inference objective that we name latent overshooting.
Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models.
Planet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.most modern supervised statistical/machine learning (ml) methods are explicitly designed to solve prediction problems very well.
Achieving this goal does not imply that these methods automatically deliver good estimators of causal parameters.
Examples of such parameters include individual regression coefficients, average treatment effects, average lifts, and demand or supply elasticities.
In fact, estimates of such causal parameters obtained via naively plugging ml estimators into estimating equations for such parameters can behave very poorly due to the regularization bias.
Fortunately, this regularization bias can be removed by solving auxiliary prediction problems via ml tools.
Specifically, we can form an orthogonal score for the target low-dimensional parameter by combining auxiliary and main ml predictions.
The score is then used to build a de-biased estimator of the target parameter which typically will converge at the fastest possible 1/root(n) rate and be approximately unbiased and normal, and from which valid confidence intervals for these parameters of interest may be constructed.
The resulting method thus could be called a "double ml" method because it relies on estimating primary and auxiliary predictive models.
In order to avoid overfitting, our construction also makes use of the k-fold sample splitting, which we call cross-fitting.
This allows us to use a very broad set of ml predictive methods in solving the auxiliary and main prediction problems, such as random forest, lasso, ridge, deep neural nets, boosted trees, as well as various hybrids and aggregators of these methods.for most deep learning practitioners, sequence modeling is synonymous with recurrent networks.
Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation.
Given a new sequence modeling task or dataset, which architecture should one use?
we conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling.
The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks.
Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as lstms across a diverse range of tasks and datasets, while demonstrating longer effective memory.
We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks.
To assist related work, we have made code available at this http url .we present two approaches that use unlabeled data to improve sequence learning with recurrent networks.
The first approach is to predict what comes next in a sequence, which is a conventional language model in natural language processing.
The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again.
These two algorithms can be used as a "pretraining" step for a later supervised sequence learning algorithm.
In other words, the parameters obtained from the unsupervised step can be used as a starting point for other supervised training models.
In our experiments, we find that long short term memory recurrent networks after being pretrained with the two approaches are more stable and generalize better.
With pretraining, we are able to train long short term memory recurrent networks up to a few hundred timesteps, thereby achieving strong performance in many text classification tasks, such as imdb, dbpedia and 20 newsgroups.several variants of the long short-term memory (lstm) architecture for recurrent neural networks have been proposed since its inception in 1995.
In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems.
This has led to a renewed interest in understanding the role and utility of various computational components of typical lstm variants.
In this paper, we present the first large-scale analysis of eight lstm variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling.
The hyperparameters of all lstm variants for each task were optimized separately using random search, and their importance was assessed using the powerful fanova framework.
In total, we summarize the results of 5400 experimental runs (â‰ˆ15 years of cpu time), which makes our study the largest of its kind on lstm networks.
Our results show that none of the variants can improve upon the standard lstm architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components.
We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.when building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings.
Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning.
They also conflate multiple sources of error, making it hard to pinpoint model weaknesses.
We present a diagnostic dataset that tests a range of visual reasoning abilities.
It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires.
We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.scene parsing is challenging for unrestricted open vocabulary and diverse scenes.
In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (pspnet).
Our global prior representation is effective to produce good quality results on the scene parsing task, while pspnet provides a superior framework for pixel-level prediction tasks.
The proposed approach achieves state-of-the-art performance on various datasets.
It came first in imagenet scene parsing challenge 2016, pascal voc 2012 benchmark and cityscapes benchmark.
A single pspnet yields new record of miou accuracy 85.4% on pascal voc 2012 and accuracy 80.2% on cityscapes.automated data-driven decision making systems are increasingly being used to assist, or even replace humans in many settings.
These systems function by learning from historical decisions, often taken by humans.
In order to maximize the utility of these systems (or, classifiers), their training involves minimizing the errors (or, misclassifications) over the given historical data.
However, it is quite possible that the optimally trained classifier makes decisions for people belonging to different social groups with different misclassification rates (e.g., misclassification rates for females are higher than for males), thereby placing these groups at an unfair disadvantage.
To account for and avoid such unfairness, in this paper, we introduce a new notion of unfairness, disparate mistreatment, which is defined in terms of misclassification rates.
We then propose intuitive measures of disparate mistreatment for decision boundary-based classifiers, which can be easily incorporated into their formulation as convex-concave constraints.
Experiments on synthetic as well as real world datasets show that our methodology is effective at avoiding disparate mistreatment, often at a small cost in terms of accuracy.we consider image transformation problems, where an input image is transformed into an output image.
Recent methods for such problems typically train feed-forward convolutional neural networks using a \emph{per-pixel} loss between the output and ground-truth images.
Parallel work has shown that high-quality images can be generated by defining and optimizing \emph{perceptual} loss functions based on high-level features extracted from pretrained networks.
We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks.
We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by gatys et al in real-time.
Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster.
We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.deep reinforcement learning has yielded proficient controllers for complex tasks.
However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point.
To address these shortcomings, this article investigates the effects of adding recurrency to a deep q-network (dqn) by replacing the first post-convolutional fully-connected layer with a recurrent lstm.
The resulting \textit{deep recurrent q-network} (drqn), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates dqn's performance on standard atari games and partially observed equivalents featuring flickering game screens.
Additionally, when trained with partial observations and evaluated with incrementally more complete observations, drqn's performance scales as a function of observability.
Conversely, when trained with full observations and evaluated with partial observations, drqn's performance degrades less than dqn's.
Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the dqn's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing.
In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image.
The model is trained to maximize the likelihood of the target description sentence given the training image.
Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions.
Our model is often quite accurate, which we verify both qualitatively and quantitatively.
For instance, while the current state-of-the-art bleu-1 score (the higher the better) on the pascal dataset is 25, our approach yields 59, to be compared to human performance around 69.
We also show bleu-1 score improvements on flickr30k, from 56 to 66, and on sbu, from 19 to 28.
Lastly, on the newly released coco dataset, we achieve a bleu-4 of 27.7, which is the current state-of-the-art.we present the stanford question answering dataset (squad), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage.
We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees.
We build a strong logistic regression model, which achieves an f1 score of 51.0%, a significant improvement over a simple baseline (20%).
However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research.
The dataset is freely available at https://stanford-qa.commany robotic planning applications involve continuous actions with highly non-linear constraints, which cannot be modeled using modern planners that construct a propositional representation.
We introduce stripstream: an extension of the strips language which can model these domains by supporting the specification of blackbox generators to handle complex constraints.
The outputs of these generators interact with actions through possibly infinite streams of objects and static predicates.
We provide two algorithms which both reduce stripstream problems to a sequence of finite-domain planning problems.
The representation and algorithms are entirely domain independent.
We demonstrate our framework on simple illustrative domains, and then on a high-dimensional, continuous robotic task and motion planning domain.neural machine translation (nmt) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems.
Unfortunately, nmt systems are known to be computationally expensive both in training and in translation inference.
Also, most nmt systems have difficulty with rare words.
These issues have hindered nmt's use in practical deployments and services, where both accuracy and speed are essential.
In this work, we present gnmt, google's neural machine translation system, which attempts to address many of these issues.
Our model consists of a deep lstm network with 8 encoder and 8 decoder layers using attention and residual connections.
To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder.
To accelerate the final translation speed, we employ low-precision arithmetic during inference computations.
To improve handling of rare words, we divide words into a limited set of common sub-word units ("wordpieces") for both input and output.
This method provides a good balance between the flexibility of "character"-delimited models and the efficiency of "word"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system.
Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence.
On the wmt'14 english-to-french and english-to-german benchmarks, gnmt achieves competitive results to state-of-the-art.
Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to google's phrase-based production system.we report on a series of experiments with convolutional neural networks (cnn) trained on top of pre-trained word vectors for sentence-level classification tasks.
We show that a simple cnn with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.
Learning task-specific vectors through fine-tuning offers further gains in performance.
We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.
The cnn models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.generative adversarial networks (gans) excel at creating realistic images with complex models for which maximum likelihood is infeasible.
However, the convergence of gan training has still not been proved.
We propose a two time-scale update rule (ttur) for training gans with stochastic gradient descent on arbitrary gan loss functions.
Ttur has an individual learning rate for both the discriminator and the generator.
Using the theory of stochastic approximation, we prove that the ttur converges under mild assumptions to a stationary local nash equilibrium.
The convergence carries over to the popular adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape.
For the evaluation of the performance of gans at image generation, we introduce the "fr\'echet inception distance" (fid) which captures the similarity of generated images to real ones better than the inception score.
In experiments, ttur improves learning for dcgans and improved wasserstein gans (wgan-gp) outperforming conventional gan training on celeba, cifar-10, svhn, lsun bedrooms, and the one billion word benchmark.predicting protein properties such as solvent accessibility and secondary structure from its primary amino acid sequence is an important task in bioinformatics.
Recently, a few deep learning models have surpassed the traditional window based multilayer perceptron.
Taking inspiration from the image classification domain we propose a deep convolutional neural network architecture, must-cnn, to predict protein properties.
This architecture uses a novel multilayer shift-and-stitch (must) technique to generate fully dense per-position predictions on protein sequences.
Our model is significantly simpler than the state-of-the-art, yet achieves better results.
By combining must and the efficient convolution operation, we can consider far more parameters while retaining very fast prediction speeds.
We beat the state-of-the-art performance on two large protein property prediction datasets.learning from a few examples remains a key challenge in machine learning.
Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data.
In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories.
Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types.
We then define one-shot learning problems on vision (using omniglot, imagenet) and language tasks.
Our algorithm improves one-shot accuracy on imagenet from 87.6% to 93.2% and from 88.0% to 93.8% on omniglot compared to competing approaches.
We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the penn treebank.we present deepwalk, a novel approach for learning latent representations of vertices in a network.
These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models.
Deepwalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs.
Deepwalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences.
We demonstrate deepwalk's latent representations on several multi-label network classification tasks for social networks such as blogcatalog, flickr, and youtube.
Our results show that deepwalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information.
Deepwalk's representations can provide f1 scores up to 10% higher than competing methods when labeled data is sparse.
In some experiments, deepwalk's representations are able to outperform all baseline methods while using 60% less training data.
Deepwalk is also scalable.
It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable.
These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.we present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (gans) framework.
We focus on two applications of gans: semi-supervised learning, and the generation of images that humans find visually realistic.
Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels.
Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on mnist, cifar-10 and svhn.
The generated images are of high quality as confirmed by a visual turing test: our model generates mnist samples that humans cannot distinguish from real data, and cifar-10 samples that yield a human error rate of 21.3%.
We also present imagenet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of imagenet classes.generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs.
Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort.
With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features.
However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank.
In this paper, we present wide & deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems.
We productionized and evaluated the system on google play, a commercial mobile app store with over one billion active users and over one million apps.
Online experiment results show that wide & deep significantly increased app acquisitions compared with wide-only and deep-only models.
We have also open-sourced our implementation in tensorflow.we propose a simple but strong baseline for time series classification from scratch with deep neural networks.
Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting.
The proposed fully convolutional network (fcn) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the resnet structure is also competitive.
The global average pooling in our convolutional model enables the exploitation of the class activation map (cam) to find out the contributing region in the raw data for the specific labels.
Our models provides a simple choice for the real world application and a good starting point for the future research.
An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classification semantics.we introduce a neural architecture for navigation in novel environments.
Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment.
The cognitive mapper and planner (cmp) is based on two key ideas: a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the task, and b) a spatial memory with the ability to plan given an incomplete set of observations about the world.
Cmp constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step.
The accumulated belief of the world enables the agent to track visited regions of the environment.
We train and test cmp on navigation problems in simulation environments derived from scans of real world buildings.
Our experiments demonstrate that cmp outperforms alternate learning-based architectures, as well as, classical mapping and path planning approaches in many cases.
Furthermore, it naturally extends to semantically specified goals, such as 'going to a chair'.
We also deploy cmp on physical robots in indoor environments, where it achieves reasonable performance, even though it is trained entirely in simulation.multivariate time series forecasting is an important machine learning problem across many domains, including predictions of solar plant energy output, electricity consumption, and traffic jam situation.
Temporal data arise in these real-world applications often involves a mixture of long-term and short-term patterns, for which traditional approaches such as autoregressive models and gaussian process may fail.
In this paper, we proposed a novel deep learning framework, namely long- and short-term time-series network (lstnet), to address this open challenge.
Lstnet uses the convolution neural network (cnn) and the recurrent neural network (rnn) to extract short-term local dependency patterns among variables and to discover long-term patterns for time series trends.
Furthermore, we leverage traditional autoregressive model to tackle the scale insensitive problem of the neural network model.
In our evaluation on real-world data with complex mixtures of repetitive patterns, lstnet achieved significant performance improvements over that of several state-of-the-art baseline methods.
All the data and experiment codes are available online.in recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing.
However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny.
In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation -- collaborative filtering -- on the basis of implicit feedback.
Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics.
When it comes to model the key factor in collaborative filtering -- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.
By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named ncf, short for neural network-based collaborative filtering.
Ncf is generic and can express and generalize matrix factorization under its framework.
To supercharge ncf modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function.
Extensive experiments on two real-world datasets show significant improvements of our proposed ncf framework over the state-of-the-art methods.
Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.deeper neural networks are more difficult to train.
We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.
We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions.
We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth.
On the imagenet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than vgg nets but still having lower complexity.
An ensemble of these residual nets achieves 3.57% error on the imagenet test set.
This result won the 1st place on the ilsvrc 2015 classification task.
We also present analysis on cifar-10 with 100 and 1000 layers.
The depth of representations is of central importance for many visual recognition tasks.
Solely due to our extremely deep representations, we obtain a 28% relative improvement on the coco object detection dataset.
Deep residual nets are foundations of our submissions to ilsvrc & coco 2015 competitions, where we also won the 1st places on the tasks of imagenet detection, imagenet localization, coco detection, and coco segmentation.the state of the art in music source separation employs neural networks trained in a supervised fashion on multi-track databases to estimate the sources from a given mixture.
With only few datasets available, often extensive data augmentation is used to combat overfitting.
Mixing random tracks, however, can even reduce separation performance as instruments in real music are strongly correlated.
The key concept in our approach is that source estimates of an optimal separator should be indistinguishable from real source signals.
Based on this idea, we drive the separator towards outputs deemed as realistic by discriminator networks that are trained to tell apart real from separator samples.
This way, we can also use unpaired source and mixture recordings without the drawbacks of creating unrealistic music mixtures.
Our framework is widely applicable as it does not assume a specific network architecture or number of sources.
To our knowledge, this is the first adoption of adversarial training for music source separation.
In a prototype experiment for singing voice separation, separation performance increases with our approach compared to purely supervised training.with the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners.
To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings.
Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering.
In this work, we present a shared variable neural network model called proje that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph's entities and edges, and through subtle, but important, changes to the standard loss function.
In doing so, proje has a parameter size that is smaller than 11 out of 15 existing methods while performing 37% better than the current-best method on standard datasets.
We also show, via a new fact checking task, that proje is capable of accurately determining the veracity of many declarative statements.there is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education.
In particular, individual-level causal inference has important applications such as precision medicine.
We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ite) from observational data, under the assumption known as strong ignorability.
The algorithms learn a "balanced" representation such that the induced treated and control distributions look similar.
We give a novel, simple and intuitive generalization-error bound showing that the expected ite estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation.
We use integral probability metrics to measure distances between distributions, deriving explicit bounds for the wasserstein and maximum mean discrepancy (mmd) distances.
Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.we present orb-slam2 a complete slam system for monocular, stereo and rgb-d cameras, including map reuse, loop closing and relocalization capabilities.
The system works in real-time on standard cpus in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city.
Our back-end based on bundle adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale.
Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization.
The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate slam solution.
We publish the source code, not only for the benefit of the slam community, but with the aim of being an out-of-the-box slam solution for researchers in other fields.learning individual-level causal effects from observational data, such as inferring the most effective medication for a specific patient, is a problem of growing importance for policy makers.
The most important aspect of inferring causal effects from observational data is the handling of confounders, factors that affect both an intervention and its outcome.
A carefully designed observational study attempts to measure all important confounders.
However, even if one does not have direct access to all confounders, there may exist noisy and uncertain measurement of proxies for confounders.
We build on recent advances in latent variable modeling to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect.
Our method is based on variational autoencoders (vae) which follow the causal structure of inference with proxies.
We show our method is significantly more robust than existing methods, and matches the state-of-the-art on previous benchmarks focused on individual treatment effects.knowledge graph completion aims to perform link prediction between entities.
In this paper, we consider the approach of knowledge graph embeddings.
Recently, models such as transe and transh build entity and relation embeddings by regarding a relation as translation from head entity to tail entity.
We note that these models simply put both entities and relations within the same semantic space.
In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling.
In this paper, we propose transr to build entity and relation embeddings in separate entity space and relation spaces.
Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities.
In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction.
Experimental results show significant and consistent improvements compared to state-of-the-art baselines including transe and transh.
The source code of this paper can be obtained from https://github.com/mrlyk423/relation_extraction.we develop a bayesian "sum-of-trees" model where each tree is constrained by a regularization prior to be a weak learner, and fitting and inference are accomplished via an iterative bayesian backfitting mcmc algorithm that generates samples from a posterior.
Effectively, bart is a nonparametric bayesian regression approach which uses dimensionally adaptive random basis elements.
Motivated by ensemble methods in general, and boosting algorithms in particular, bart is defined by a statistical model: a prior and a likelihood.
This approach enables full posterior inference including point and interval estimates of the unknown regression function as well as the marginal effects of potential predictors.
By keeping track of predictor inclusion frequencies, bart can also be used for model-free variable selection.
Bart's many features are illustrated with a bake-off against competing methods on 42 different data sets, with a simulation experiment and on a drug discovery classification problem.machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing.
In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation.
Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices.
In this paper, we develop a framework for modeling fairness using tools from causal inference.
Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group.
We demonstrate our framework on a real-world problem of fair prediction of success in law school.this paper studies monocular visual odometry (vo) problem.
Most of existing vo algorithms are developed under a standard pipeline including feature extraction, feature matching, motion estimation, local optimisation, etc.
Although some of them have demonstrated superior performance, they usually need to be carefully designed and specifically fine-tuned to work well in different environments.
Some prior knowledge is also required to recover an absolute scale for monocular vo.
This paper presents a novel end-to-end framework for monocular vo by using deep recurrent convolutional neural networks (rcnns).
Since it is trained and deployed in an end-to-end manner, it infers poses directly from a sequence of raw rgb images (videos) without adopting any module in the conventional vo pipeline.
Based on the rcnns, it not only automatically learns effective feature representation for the vo problem through convolutional neural networks, but also implicitly models sequential dynamics and relations using deep recurrent neural networks.
Extensive experiments on the kitti vo dataset show competitive performance to state-of-the-art methods, verifying that the end-to-end deep learning technique can be a viable complement to the traditional vo systems.non-negative matrix factorization (nmf) approximates a given matrix as a product of two non-negative matrices.
Multiplicative algorithms deliver reliable results, but they show slow convergence for high-dimensional data and may be stuck away from local minima.
Gradient descent methods have better behavior, but only apply to smooth losses such as the least-squares loss.
In this article, we propose a first-order primal-dual algorithm for non-negative decomposition problems (where one factor is fixed) with the kl divergence, based on the chambolle-pock algorithm.
All required computations may be obtained in closed form and we provide an efficient heuristic way to select step-sizes.
By using alternating optimization, our algorithm readily extends to nmf and, on synthetic examples, face recognition or music source separation datasets, it is either faster than existing algorithms, or leads to improved local optima, or both.generative adversarial networks (gans) are powerful generative models, but suffer from training instability.
The recently proposed wasserstein gan (wgan) makes progress toward stable training of gans, but sometimes can still generate only low-quality samples or fail to converge.
We find that these problems are often due to the use of weight clipping in wgan to enforce a lipschitz constraint on the critic, which can lead to undesired behavior.
We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input.
Our proposed method performs better than standard wgan and enables stable training of a wide variety of gan architectures with almost no hyperparameter tuning, including 101-layer resnets and language models over discrete data.
We also achieve high quality generations on cifar-10 and lsun bedrooms.we adapt the ideas underlying the success of deep q-learning to the continuous action domain.
We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces.
Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving.
Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives.
We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.in recent years, supervised learning with convolutional networks (cnns) has seen huge adoption in computer vision applications.
Comparatively, unsupervised learning with cnns has received less attention.
In this work we hope to help bridge the gap between the success of cnns for supervised learning and unsupervised learning.
We introduce a class of cnns called deep convolutional generative adversarial networks (dcgans), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning.
Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator.
Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science.
Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature.
These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph.
At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach.
In this paper, we reformulate existing models into a single common framework we call message passing neural networks (mpnns) and explore additional novel variations within this framework.
Using mpnns we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.there is large consent that successful training of deep networks requires many thousand annotated training samples.
In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.
The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization.
We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the isbi challenge for segmentation of neuronal structures in electron microscopic stacks.
Using the same network trained on transmitted light microscopy images (phase contrast and dic) we won the isbi cell tracking challenge 2015 in these categories by a large margin.
Moreover, the network is fast.
Segmentation of a 512x512 image takes less than a second on a recent gpu.
The full implementation (based on caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .
